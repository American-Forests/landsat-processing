{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Rohit Musti\n",
    "# rmusti@americanforests.org\n",
    "####\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import rasterstats as rs\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"setting file paths\")\n",
    "home_dir = \"Y:/CommunityReLeaf/TreeEquityScore/\"\n",
    "census_block_groups_dir = home_dir + \"CensusBlockGroups/\"\n",
    "ards_path = home_dir + \"landsat/ards/\"\n",
    "wrs_path = home_dir + \"landsat/wrs2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine What Data to Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ards = gpd.GeoDataFrame.from_file(ards_path)\n",
    "wrs = gpd.GeoDataFrame.from_file(wrs_path)\n",
    "\n",
    "ards = ards.to_crs(wrs.crs)\n",
    "res = gpd.sjoin(ards, wrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data for amazon's s3 landsat bucket\n",
    "print(\"pulling scenes from amazon\")\n",
    "s3_scenes = pd.read_csv('http://landsat-pds.s3.amazonaws.com/c1/L8/scene_list.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFromARDStoWRS2(h,v):\n",
    "    '''\n",
    "    author: rmusti\n",
    "    args: h (the h from ards file), v (the v from ards file)\n",
    "    returns: a list of (path, row) coordinates that intersect with the ards block\n",
    "    '''\n",
    "    res_temp = res[res.h==h]\n",
    "    res_temp = res_temp[res_temp.v==v]\n",
    "    return list(pd.DataFrame(res_temp.groupby(['PATH', 'ROW'])).iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pras = {}\n",
    "for i in tqdm(os.listdir(f\"{home_dir}clipped_block_groups\")):\n",
    "    if i==\"ak\" or i ==\"hi\" or i != \"il\": continue\n",
    "    filename = f\"{home_dir}clipped_block_groups/{i}/{i}_ed.shp\"\n",
    "    focus_area = gpd.read_file(filename)\n",
    "    ards = ards.to_crs(focus_area.crs)\n",
    "    ards_intersection = gpd.sjoin(focus_area, ards, how='left', op='intersects')\n",
    "    unique_hvs = list(pd.DataFrame(ards_intersection.groupby([\"h\", \"v\"])).iloc[:,0])\n",
    "    unique_path_rows = []\n",
    "    for h,v in unique_hvs:\n",
    "        unique_path_rows.extend(convertFromARDStoWRS2(h, v))\n",
    "    unique_path_rows = list(set(unique_path_rows))\n",
    "    pras[i] = unique_path_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_month = 6\n",
    "end_month = 10\n",
    "cloud_cover_threshold = 25\n",
    "state_scenes = {}\n",
    "num_scenes = 5\n",
    "for i in pras.keys():\n",
    "    state_list = []\n",
    "    for path, row in (pras[i]):\n",
    "        scenes = s3_scenes[(s3_scenes.path == path) & (s3_scenes.row == row) & \n",
    "                           (s3_scenes.cloudCover <= cloud_cover_threshold) & \n",
    "                           (~s3_scenes.productId.str.contains('_T2')) & (~s3_scenes.productId.str.contains('_RT'))]\n",
    "        scenes['acquisitionMonth'] = scenes.acquisitionDate.str.split(\"-\").str[1].astype(int) # extract month\n",
    "        scenes = scenes[(scenes.acquisitionMonth >= start_month) & (scenes.acquisitionMonth <= end_month)] # only scenes in month range\n",
    "        scenes = scenes.sort_values(\"cloudCover\", ascending=True).iloc[:num_scenes]\n",
    "        state_list.append(scenes)\n",
    "        if len(scenes) == 0: print(i, path, row, len(scenes)>0)\n",
    "    state_list = pd.concat(state_list)\n",
    "    state_scenes[i] = state_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(state_scenes):\n",
    "    if i not in os.listdir(home_dir+\"landsat\"):\n",
    "        folder = home_dir+f\"landsat/{i}\"\n",
    "        os.mkdir(folder, 0o666)\n",
    "    for _, row in tqdm(state_scenes[i].iterrows()):\n",
    "        if row.productId in os.listdir(f\"{home_dir}/landsat/{i}/\"): continue\n",
    "        response = requests.get(row.download_url)\n",
    "\n",
    "        # If the response status code is fine (200)\n",
    "        if response.status_code == 200:\n",
    "            # Import the html to beautiful soup\n",
    "            html = BeautifulSoup(response.content, 'html.parser')\n",
    "            # Create the dir where we will put this image files.\n",
    "            entity_dir = os.path.join(f\"{home_dir}/landsat/{i}/\", row.productId)\n",
    "            os.makedirs(entity_dir, exist_ok=True)\n",
    "\n",
    "            # Second loop: for each band of this image that we find using the html <li> tag\n",
    "            for li in html.find_all('li'):\n",
    "                    # Get the href tag\n",
    "                current_file = li.find_next('a').get('href')\n",
    "                if \"B10.TIF\" in current_file or \"B11.TIF\" in current_file or \"MTL\" in current_file:\n",
    "                    response = requests.get(row.download_url.replace('index.html', current_file), stream=True)\n",
    "                    with open(os.path.join(entity_dir, current_file), 'wb') as output:\n",
    "                        shutil.copyfileobj(response.raw, output)\n",
    "                    del response\n",
    "        else:\n",
    "            print('error:',response)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Downloaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature calculation for a raster file\n",
    "\n",
    "def temp_calc(constants_dict, band10, band11, kelvin_constant=273.15):\n",
    "    band10_radiance = float(constants_dict['RADIANCE_MULT_BAND_10'])*band10 + float(constants_dict['RADIANCE_ADD_BAND_10'])\n",
    "    band11_radiance = float(constants_dict['RADIANCE_MULT_BAND_11'])*band11 + float(constants_dict['RADIANCE_ADD_BAND_11'])\n",
    "\n",
    "    # TODO: convert this to a lambda function\n",
    "    band10_sattemp = (float(constants_dict['K2_CONSTANT_BAND_10']) / np.log((float(   constants_dict['K1_CONSTANT_BAND_10'])/band10_radiance) + 1)) - kelvin_constant \n",
    "    band11_sattemp = (float(constants_dict['K2_CONSTANT_BAND_11']) / np.log((float(constants_dict['K1_CONSTANT_BAND_11'])/band11_radiance) + 1)) - kelvin_constant \n",
    "\n",
    "    # TODO: convert this to a lambda function\n",
    "    band10_sattemp_far = (band10_sattemp * 1.8) + 32\n",
    "    band11_sattemp_far = (band11_sattemp * 1.8) + 32\n",
    "\n",
    "    sattemp_avg = (band10_sattemp + band11_sattemp) / 2.0\n",
    "    sattemp_avg_far = (band10_sattemp_far + band11_sattemp_far) / 2.0\n",
    "    return sattemp_avg_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(landsat_raw, current_band):\n",
    "    current_bands_path = os.path.join(landsat_raw, current_band)\n",
    "    current_bands = [i for i in os.listdir(current_bands_path) if 'ovr' not in i]\n",
    "    bands10 = [i for i in current_bands if 'B10' in i]\n",
    "    bands11 = [i for i in current_bands if 'B11' in i]\n",
    "    bands_meta = [i for i in current_bands if 'MTL' in i]\n",
    "    assert(len(bands10)== len(bands11) == len(bands_meta)==1)\n",
    "    band10_path = os.path.join(current_bands_path, bands10[0])\n",
    "    band11_path = os.path.join(current_bands_path, bands11[0])\n",
    "    bands_meta_path = os.path.join(current_bands_path, bands_meta[0])\n",
    "    return (band10_path, band11_path, bands_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(os.listdir(home_dir+\"landsat\")):\n",
    "    if len(i) != 2: continue\n",
    "    print(\"processing\", i)\n",
    "    for q in (os.listdir(home_dir+f\"landsat/{i}\")):\n",
    "        if 'temperature.tif' in os.listdir(f'{home_dir}landsat/{i}/{q}'): continue\n",
    "        band10_path, band11_path, bands_meta_path = get_bands(f\"{home_dir}landsat/{i}\", q)\n",
    "        with rio.open(band10_path) as band10_in, rio.open(band11_path) as band11_in, open(bands_meta_path, 'r') as band_meta_in:\n",
    "            target_crs = band10_in.profile['crs']\n",
    "            bands_meta = band10_in\n",
    "            band10 = band10_in.read()\n",
    "            band11 = band11_in.read()\n",
    "            band_meta = [i.split() for i in band_meta_in.readlines()]\n",
    "            band10 = np.ma.masked_array(band10, mask=(band10 == 0)).astype(float)\n",
    "            band11 = np.ma.masked_array(band11, mask=(band11 == 0)).astype(float)\n",
    "            constants_dict = {i[0]:i[-1] for i in band_meta}\n",
    "            temperature_frame = temp_calc(constants_dict,band10,band11)\n",
    "            temperature_frame[temperature_frame > 110] = -999 # set to no data\n",
    "            temperature_frame[temperature_frame < 40] = -999 # set to no data\n",
    "            with rio.Env():\n",
    "                profile = band10_in.profile\n",
    "                profile.update(\n",
    "                    dtype=rio.uint8,\n",
    "                    count=1,\n",
    "                    compress='lzw')\n",
    "                with rio.open(f'{home_dir}landsat/{i}/{q}/temperature.tif', 'w', **profile) as dst:\n",
    "                    dst.write(temperature_frame.astype(rio.uint8))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ([q for q in os.listdir(home_dir+\"landsat\") if len(q)<=2]):\n",
    "    state = gpd.read_file(f\"{home_dir}clipped_block_groups/{i}/{i}_ed.shp\")\n",
    "    counter = 0\n",
    "    print(f'processing {i}')\n",
    "    for frame in tqdm([z for z in os.listdir(f\"{home_dir}landsat/{i}/groups/\") if '.tif' in z and 'tif.' not in z]):\n",
    "        temperature_path = f\"{home_dir}landsat/{i}/groups/{frame}\"\n",
    "        with rio.open(temperature_path) as temperature_in:\n",
    "            target_crs = temperature_in.profile['crs']\n",
    "            state = state.to_crs(target_crs)\n",
    "            temperature_meta = temperature_in\n",
    "            temperature = temperature_in.read()\n",
    "            temperature[temperature==25] = 0\n",
    "            state = rs.zonal_stats(state, temperature[0],\n",
    "                                                  nodata=0,\n",
    "                                                  affine=temperature_in.profile['transform'],\n",
    "                                                  geojson_out=True, copy_properties=True,\n",
    "                                                  stats=\"mean\")\n",
    "            state = gpd.GeoDataFrame.from_features(state, crs=target_crs)\n",
    "            state = state.rename(columns={'mean':f'temp_{frame}'})\n",
    "            counter += 1\n",
    "    state['avg_temp'] = state[[i for i in state.columns if 'temp' in i]].mean(axis=1)\n",
    "    state.to_csv(f\"{home_dir}clipped_block_groups_temperature/{i}_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
